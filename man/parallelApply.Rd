% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{parallelApply}
\alias{parallelApply}
\title{Applies a function on each row or column of a matrix in parallel.}
\usage{
parallelApply(X, MARGIN, FUN, nTasks = nCores,
  nCores = parallel::detectCores(), ...)
}
\arguments{
\item{X}{A matrix.}

\item{MARGIN}{The subscripts which the function will be applied over. 1
indicates rows, 2 indicates columns.}

\item{FUN}{The function to be applied.}

\item{nTasks}{The number of tasks the problem should be broken into to be
distributed among \code{nCores} cores. Defaults to \code{nCores}.}

\item{nCores}{The number of cores (passed to
\code{\link[parallel]{mclapply}}).}

\item{...}{Additional arguments to be passed to \code{apply}.}
}
\description{
The input matrix \code{X} is broken into \code{nTasks} chunks and passed to
\code{\link[parallel]{mclapply}}. The number of cores can be configured using
\code{nCores}.
}
\details{
\code{nTasks} has to be chosen carefully to avoid running out of memory. As a
rule of thumb, at least around \code{object_size(X) + (nCores *
(object_size(X) / nTasks)) + object_size(result)} MB of total memory will be
needed, not including potential copies of your data that might be created
(for example \code{lsfit} runs \code{cbind(1, X)}). Therefore, for 20 nodes
and 20 tasks you will need at least \code{2 * object_size(X)} MB, for 20
nodes and 40 tasks \code{1.5 * object_size(X)} MB, etc.

If \code{nTasks} equals 1, the regular \code{apply} function will be called
to preserve memory.
}

